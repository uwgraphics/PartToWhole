@article{allen2017ReferenceDependentPreferencesEvidence,
  title = {Reference-{{Dependent Preferences}}: {{Evidence}} from {{Marathon Runners}}},
  shorttitle = {Reference-{{Dependent Preferences}}},
  author = {Allen, Eric J. and Dechow, Patricia M. and Pope, Devin G. and Wu, George},
  year = {2017},
  month = jun,
  journal = {Management Science},
  volume = {63},
  number = {6},
  pages = {1657--1672},
  publisher = {INFORMS},
  issn = {0025-1909},
  doi = {10.1287/mnsc.2015.2417},
  urldate = {2024-03-22},
  abstract = {Theories of reference-dependent preferences propose that individuals evaluate outcomes as gains or losses relative to a neutral reference point. We test for reference dependence in a large data set of marathon finishing times (n = 9,789,093). Models of reference-dependent preferences such as prospect theory predict bunching of finishing times at reference points. We provide visual and statistical evidence that round numbers (e.g., a four-hour marathon) serve as reference points in this environment and as a result produce significant bunching of performance at these round numbers. Bunching is driven by planning and adjustments in effort provision near the finish line and cannot be explained by explicit rewards (e.g., qualifying for the Boston Marathon), peer effects, or institutional features (e.g., pacesetters). Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2015.2417. This paper was accepted by John List, behavioral economics.},
  keywords = {bunching,effort provision,loss aversion,prospect theory,reference dependence}
}

@inproceedings{cho2017AnchoringEffectDecisionMaking,
  title = {The {{Anchoring Effect}} in {{Decision-Making}} with {{Visual Analytics}}},
  booktitle = {2017 {{IEEE Conference}} on {{Visual Analytics Science}} and {{Technology}} ({{VAST}})},
  author = {Cho, Isaac and Wesslen, Ryan and Karduni, Alireza and Santhanam, Sashank and Shaikh, Samira and Dou, Wenwen},
  year = {2017},
  month = oct,
  pages = {116--126},
  doi = {10.1109/VAST.2017.8585665},
  urldate = {2024-03-20},
  abstract = {Anchoring effect is the tendency to focus too heavily on one piece of information when making decisions. In this paper, we present a novel, systematic study and resulting analyses that investigate the effects of anchoring effect on human decision-making using visual analytic systems. Visual analytics interfaces typically contain multiple views that present various aspects of information such as spatial, temporal, and categorical. These views are designed to present complex, heterogeneous data in accessible forms that aid decision-making. However, human decision-making is often hindered by the use of heuristics, or cognitive biases, such as anchoring effect. Anchoring effect can be triggered by the order in which information is presented or the magnitude of information presented. Through carefully designed laboratory experiments, we present evidence of anchoring effect in analysis with visual analytics interfaces when users are primed by representation of different pieces of information. We also describe detailed analyses of users' interaction logs which reveal the impact of anchoring bias on the visual representation preferred and paths of analysis. We discuss implications for future research to possibly detect and alleviate anchoring bias.},
  keywords = {Analytical models,Anchoring Effect,Cognitive Bias,Data visualization,Decision making,Interaction Log Analysis,K.6.1 [Management of Computing and Information Systems]: Project and People Management-Life Cycle,K.7.m [The Computing Profession]: Miscellaneous-Ethics,Sense Making,Task analysis,Uncertainty,Visual analytics,Visual Analytics}
}

@article{cleveland1984GraphicalPerceptionTheory,
  title = {Graphical {{Perception}}: {{Theory}}, {{Experimentation}}, and {{Application}} to the {{Development}} of {{Graphical Methods}}},
  shorttitle = {Graphical {{Perception}}},
  author = {Cleveland, William S. and McGill, Robert},
  year = {1984},
  journal = {Journal of the American Statistical Association},
  volume = {79},
  number = {387},
  eprint = {2288400},
  eprinttype = {jstor},
  pages = {531--554},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2288400},
  urldate = {2024-03-18},
  abstract = {The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception-the visual decoding of information encoded on graphs-and it includes both theory and experimentation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be expanded. The theory provides a guideline for graph construction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The conclusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms-dot charts, dot charts with grouping, and framed-rectangle charts.}
}

@article{cleveland1985GraphicalPerceptionGraphical,
  title = {Graphical {{Perception}} and {{Graphical Methods}} for {{Analyzing Scientific Data}}},
  author = {Cleveland, William S. and McGill, Robert},
  year = {1985},
  journal = {Science},
  volume = {229},
  number = {4716},
  eprint = {1695272},
  eprinttype = {jstor},
  pages = {828--833},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  urldate = {2024-03-12},
  doi = {https://doi.org/10.1126/science.229.4716.828},
  abstract = {Graphical perception is the visual decoding of the quantitative and qualitative information encoded on graphs. Recent investigations have uncovered basic principles of human graphical perception that have important implications for the display of data. The computer graphics revolution has stimulated the invention of many graphical methods for analyzing and presenting scientific data, such as box plots, two-tiered error bars, scatterplot smoothing, dot charts, and graphing on a log base 2 scale.}
}

@article{cleveland1987GraphicalPerceptionVisual,
  title = {Graphical {{Perception}}: {{The Visual Decoding}} of {{Quantitative Information}} on {{Graphical Displays}} of {{Data}}},
  shorttitle = {Graphical {{Perception}}},
  author = {Cleveland, William S. and McGill, Robert},
  year = {1987},
  journal = {Journal of the Royal Statistical Society. Series A (General)},
  volume = {150},
  number = {3},
  eprint = {2981473},
  eprinttype = {jstor},
  pages = {192--229},
  publisher = {[Royal Statistical Society, Wiley]},
  issn = {0035-9238},
  doi = {10.2307/2981473},
  urldate = {2024-03-18},
  abstract = {Studies in graphical perception, both theoretical and experimental, provide a scientific foundation for the construction area of statistical graphics. From these studies a paradigm that has important applications for practice has begun to emerge. The paradigm is based on elementary codes: Basic geometric and textural aspects of a graph that encode the quantitative information. The methodology that can be invoked to study graphical perception is illustrated by an investigation of the shape parameter of a two-variable graph, a topic that has had much discussion, but little scientific study, for at least 70 years.}
}

@article{converse2018RoleProminentNumbers,
  title = {The Role of ``{{Prominent Numbers}}'' in Open Numerical Judgment: {{Strained}} Decision Makers Choose from a Limited Set of Accessible Numbers},
  shorttitle = {The Role of ``{{Prominent Numbers}}'' in Open Numerical Judgment},
  author = {Converse, Benjamin A. and Dennis, Patrick J.},
  year = {2018},
  month = jul,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {147},
  pages = {94--107},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2018.05.007},
  urldate = {2024-02-14},
  abstract = {Numerate adults can represent an infinite array of integers. When a judgment requires them to ``pick a number,'' how do they select one to represent the abstract signal in mind? Drawing from research on the cognitive psychology of number representation, we conjecture that judges who operate primarily in decimal systems simplify by initially selecting from a set of chronically accessible ``Prominent Numbers'' defined as the powers of ten, their doubles, and their halves [{\dots} 5, 10, 20, 50, 100, 200{\dots}]; then, when willing and able, refining from there. A sample of 3\,billion stock trades reveals that traders' decisions reflect Prominent-Number clustering (Study 1) and a ``natural experiment'' reveals more clustering in rushed trading conditions (Study 2). Three sets of subsequent studies provide evidence consistent with an accessibility-based account of Prominent-Number usage: Experiments show that judges rely more on Prominent Numbers when they are induced to rush rather than take their time (Studies 3a and 3b), and when they are under high versus low cognitive load (Studies 4a, 4b, and 4c); and a final correlational study shows that Prominent-Number clustering is more apparent for judgments that require judges to scan a wider range of plausible values (Study 5). This work underscores the need to differentiate between Round Numbers and Prominent Numbers, and between representational properties of graininess and accessibility, in numerical judgment.},
  keywords = {Decision making,Judgment,Number representation,Prominent numbers,Round numbers}
}

@article{croxton1927BarChartsCircle,
  title = {Bar {{Charts Versus Circle Diagrams}}},
  author = {Croxton, Frederick E. and Stryker, Roy E.},
  year = {1927},
  journal = {Journal of the American Statistical Association},
  volume = {22},
  number = {160},
  eprint = {2276829},
  eprinttype = {jstor},
  pages = {473--482},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2276829},
  urldate = {2024-03-13}
}

@article{croxton1932GraphicComparisonsBars,
  title = {Graphic {{Comparisons}} by {{Bars}}, {{Squares}}, {{Circles}}, and {{Cubes}}},
  author = {Croxton, Frederick E.},
  year = {1932},
  journal = {Journal of the American Statistical Association},
  volume = {27},
  number = {177},
  eprint = {2277880},
  eprinttype = {jstor},
  pages = {54--60},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2277880},
  urldate = {2024-03-18}
}

@article{davis2024RisksRankingRevisiting,
  title = {The {{Risks}} of {{Ranking}}: {{Revisiting Graphical Perception}} to {{Model Individual Differences}} in {{Visualization Performance}}},
  shorttitle = {The {{Risks}} of {{Ranking}}},
  author = {Davis, Russell and Pu, Xiaoying and Ding, Yiren and Hall, Brian D. and Bonilla, Karen and Feng, Mi and Kay, Matthew and Harrison, Lane},
  year = {2024},
  month = mar,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {30},
  number = {3},
  pages = {1756--1771},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2022.3226463},
  urldate = {2024-03-26},
  abstract = {Graphical perception studies typically measure visualization encoding effectiveness using the error of an ``average observer'', leading to canonical rankings of encodings for numerical attributes: e.g., position {$>>$} area {$>>$} angle {$>>$} volume. Yet different people may vary in their ability to read different visualization types, leading to variance in this ranking across individuals not captured by population-level metrics using ``average observer'' models. One way we can bridge this gap is by recasting classic visual perception tasks as tools for assessing individual performance, in addition to overall visualization performance. In this article we replicate and extend Cleveland and McGill's graphical comparison experiment using Bayesian multilevel regression, using these models to explore individual differences in visualization skill from multiple perspectives. The results from experiments and modeling indicate that some people show patterns of accuracy that credibly deviate from the canonical rankings of visualization effectiveness. We discuss implications of these findings, such as a need for new ways to communicate visualization effectiveness to designers, how patterns in individuals' responses may show systematic biases and strategies in visualization judgment, and how recasting classic visual perception tasks as tools for assessing individual performance may offer new ways to quantify aspects of visualization literacy. Experiment data, source code, and analysis scripts are available at the following repository: https://osf.io/8ub7t/?view\_only=9be4798797404a4397be3c6fc2a68cc0.},
  keywords = {Bars,Correlation,Data visualization,graphical perception,individual differences,Observers,Sociology,Task analysis,Visualization}
}

@article{dimara2020TaskBasedTaxonomyCognitive,
  title = {A {{Task-Based Taxonomy}} of {{Cognitive Biases}} for {{Information Visualization}}},
  author = {Dimara, Evanthia and Franconeri, Steven and Plaisant, Catherine and Bezerianos, Anastasia and Dragicevic, Pierre},
  year = {2020},
  month = feb,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {26},
  number = {2},
  pages = {1413--1432},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2018.2872577},
  urldate = {2024-03-20},
  abstract = {Information visualization designers strive to design data displays that allow for efficient exploration, analysis, and communication of patterns in data, leading to informed decisions. Unfortunately, human judgment and decision making are imperfect and often plagued by cognitive biases. There is limited empirical research documenting how these biases affect visual data analysis activities. Existing taxonomies are organized by cognitive theories that are hard to associate with visualization tasks. Based on a survey of the literature we propose a task-based taxonomy of 154 cognitive biases organized in 7 main categories. We hope the taxonomy will help visualization researchers relate their design to the corresponding possible biases, and lead to new research that detects and addresses biased judgment and decision making in data visualization.},
  keywords = {classification,Cognition,Cognitive bias,Data visualization,decision making,Decision making,Systematics,Task analysis,taxonomy,Taxonomy,visualization,Visualization}
}

@article{eells1926RelativeMeritsCircles,
  title = {The {{Relative Merits}} of {{Circles}} and {{Bars}} for {{Representing Component Parts}}},
  author = {Eells, Walter Crosby},
  year = {1926},
  journal = {Journal of the American Statistical Association},
  volume = {21},
  number = {154},
  eprint = {2277140},
  eprinttype = {jstor},
  pages = {119--132},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2277140},
  urldate = {2024-03-06}
}

@article{furnham2011LiteratureReviewAnchoring,
  title = {A Literature Review of the Anchoring Effect},
  author = {Furnham, Adrian and Boo, Hua Chu},
  year = {2011},
  month = feb,
  journal = {The Journal of Socio-Economics},
  volume = {40},
  number = {1},
  pages = {35--42},
  issn = {1053-5357},
  doi = {10.1016/j.socec.2010.10.008},
  urldate = {2024-03-25},
  abstract = {The anchoring effect is one of the most robust cognitive heuristics. This paper reviews the literature in this area including various different models, explanations and underlying mechanisms used to explain anchoring effects. The anchoring effect is both robust and has many implications in all decision making processes. This review paper documents the many different domains and tasks in which the effect has been shown. It also considers mood and individual difference (ability, personality, information styles) correlates of anchoring as well as the effect of motivation and knowledge on decisions affected by anchoring. Finally the review looks at the applicants of the anchoring effects in everyday life.},
  keywords = {Anchoring effects,Individual differences,Rewards}
}

@inproceedings{heer2010CrowdsourcingGraphicalPerception,
  title = {Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design},
  shorttitle = {Crowdsourcing Graphical Perception},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Heer, Jeffrey and Bostock, Michael},
  year = {2010},
  month = apr,
  series = {{{CHI}} '10},
  pages = {203--212},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1753326.1753357},
  urldate = {2024-03-12},
  abstract = {Understanding perception is critical to effective visualization design. With its low cost and scalability, crowdsourcing presents an attractive option for evaluating the large design space of visualizations; however, it first requires validation. In this paper, we assess the viability of Amazon's Mechanical Turk as a platform for graphical perception experiments. We replicate previous studies of spatial encoding and luminance contrast and compare our results. We also conduct new experiments on rectangular area perception (as in treemaps or cartograms) and on chart size and gridline spacing. Our results demonstrate that crowdsourced perception experiments are viable and contribute new insights for visualization design. Lastly, we report cost and performance data from our experiments and distill recommendations for the design of crowdsourced studies.},
  isbn = {978-1-60558-929-9},
  keywords = {crowdsourcing,evaluation,experimentation,graphical perception,information visualization,mechanical turk,user study}
}

@article{hollands1998JudgingProportionGraphs,
  title = {Judging {{Proportion}} with {{Graphs}}: {{The Summation Model}}},
  shorttitle = {Judging {{Proportion}} with {{Graphs}}},
  author = {Hollands, Justin and Spence, Ian},
  year = {1998},
  month = apr,
  journal = {Applied Cognitive Psychology},
  volume = {12},
  pages = {173--190},
  doi = {https://doi.org/10.1002/(SICI)1099-0720(199804)12:2<173::AID-ACP499>3.0.CO;2-K},
  abstract = {People take longer to judge part-to-whole relationships with bar graphs than with pie charts or divided bar graphs. Subjects may perform summation operations to establish the whole with bar graphs, which would be unnecessary for other graph types depicting the whole with a single object. To test this summation model, the number of components forming the whole was varied with bars, divided bars, reference bars, and pies in three experiments. Response time increased with the number of components for bar graphs but there was little increase for other graph types in Experiment 1. An accuracy emphasis in Experiment 2 produced generally longer response times, but had little eect on the time per summation. The summation operation was not used when graphs were displayed brie{\textasciimacron}y in Experiment 3, although subjects still took longer with bars. The estimated time for a summation operation is consistent with estimates derived from other research. In general, the bar graph is not eective for proportion judgments, and its disadvantage becomes potentially greater as the number of components increases.}
}

@article{kim2018AssessingEffectsTask,
  title = {Assessing {{Effects}} of {{Task}} and {{Data Distribution}} on the {{Effectiveness}} of {{Visual Encodings}}},
  author = {Kim, Younghoon and Heer, Jeffrey},
  year = {2018},
  journal = {Computer Graphics Forum},
  volume = {37},
  number = {3},
  pages = {157--167},
  issn = {1467-8659},
  doi = {10.1111/cgf.13409},
  urldate = {2023-12-12},
  abstract = {In addition to the choice of visual encodings, the effectiveness of a data visualization may vary with the analytical task being performed and the distribution of data values. To better assess these effects and create refined rankings of visual encodings, we conduct an experiment measuring subject performance across task types (e.g., comparing individual versus aggregate values) and data distributions (e.g., with varied cardinalities and entropies). We compare performance across 12 encoding specifications of trivariate data involving 1 categorical and 2 quantitative fields, including the use of x, y, color, size, and spatial subdivision (i.e., faceting). Our results extend existing models of encoding effectiveness and suggest improved approaches for automated design. For example, we find that colored scatterplots (with positionally-coded quantities and color-coded categories) perform well for comparing individual points, but perform poorly for summary tasks as the number of categories increases.},
  copyright = {{\copyright} 2018 The Author(s) Computer Graphics Forum {\copyright} 2018 The Eurographics Association and John Wiley \& Sons Ltd. Published by John Wiley \& Sons Ltd.},
  langid = {english},
  keywords = {Categories and Subject Descriptors (according to ACM CCS),H.5.2 Information Interfaces: User Interfaces-Evaluation}
}

@book{kosara2016JudgmentErrorPie,
  title = {Judgment {{Error}} in {{Pie Chart Variations}}},
  author = {Kosara, Robert and Skau, Drew},
  year = {2016},
  publisher = {The Eurographics Association},
  issn = {-},
  doi = {10.2312/eurovisshort.20161167},
  urldate = {2024-01-19},
  abstract = {Pie charts and their variants are prevalent in business settings and many other uses, even if they are not popular with the academic community. In a recent study, we found that contrary to general belief, there is no clear evidence that these charts are read based on the central angle. Instead, area and arc length appear to be at least equally important. In this paper, we build on that study to test several pie chart variations that are popular in information graphics: exploded pie chart, pie with larger slice, elliptical pie, and square pie (in addition to a regular pie chart used as the baseline). We find that even variants that do not distort central angle cause greater error than regular pie charts. Charts that distort the shape show the highest error. Many of our predictions based on the previous study's results are borne out by this study's findings.},
  isbn = {978-3-03868-014-7},
  langid = {english},
  annotation = {Accepted: 2016-06-09T09:42:27Z}
}

@book{kosara2019CircularParttoWholeCharts,
  title = {Circular {{Part-to-Whole Charts Using}} the {{Area Visual Cue}}},
  author = {Kosara, Robert},
  year = {2019},
  publisher = {The Eurographics Association},
  doi = {10.2312/evs.20191163},
  urldate = {2024-03-12},
  abstract = {Studies of chart types can reveal unexplored design spaces, like the circular diagrams used in recent studies on pie charts. In this paper, we explore several variations of part-to-whole charts that use area to represent a fraction within a circle. We find one chart that performs very similarly to the pie chart, even though it is visually more complex. Centered shapes turn out to lead to much worse accuracy than any other stimuli, even the same shape when not centered. These first results point to the need for more systematic explorations of the design spaces around existing charts.},
  isbn = {978-3-03868-090-1},
  langid = {english},
  annotation = {Accepted: 2019-06-02T18:14:24Z}
}

@inproceedings{kosara2019EvidenceAreaPrimary,
  title = {Evidence for {{Area}} as the {{Primary Visual Cue}} in {{Pie Charts}}},
  booktitle = {2019 {{IEEE Visualization Conference}} ({{VIS}})},
  author = {Kosara, Robert},
  year = {2019},
  month = oct,
  pages = {101--105},
  doi = {10.1109/VISUAL.2019.8933547},
  urldate = {2024-03-15},
  abstract = {The long-standing assumption of angle as the primary visual cue used to read pie charts has recently been called into question. We conducted a controlled, preregistered study using parallel-projected 3D pie charts. Angle, area, and arc length differ dramatically when projected and change over a large range of values. Modeling these changes and comparing them to study participants' estimates allows us to rank the different visual cues by model fit. Area emerges as the most likely cue used to read pie charts.},
  keywords = {Analytical models,Bars,Computational modeling,Predictive models,Three-dimensional displays,Two dimensional displays,Visualization}
}

@book{kosara2019ImpactDistributionChart,
  title = {The {{Impact}} of {{Distribution}} and {{Chart Type}} on {{Part-to-Whole Comparisons}}},
  author = {Kosara, Robert},
  year = {2019},
  publisher = {The Eurographics Association},
  issn = {2019-1162},
  doi = {10.2312/evs20191162},
  urldate = {2024-03-12},
  abstract = {Pie charts and treemaps are commonly used in business settings to show part-to-whole relationships. In a study, we compare pie charts, treemaps, stacked bars, and two circular charts when answering part-to-whole questions with multiple slices and different distributions of values. We find that the circular charts, including the unusual variations, perform better than the treemap, and that their performance depends on whether participants are asked to judge the largest slice or a smaller one.},
  isbn = {978-3-03868-090-1},
  langid = {english},
  annotation = {Accepted: 2019-06-02T18:14:24Z}
}

@article{mackinlay1986AutomatingDesignGraphical,
  title = {Automating the Design of Graphical Presentations of Relational Information},
  author = {Mackinlay, Jock},
  year = {1986},
  month = apr,
  journal = {ACM Trans. Graph.},
  volume = {5},
  number = {2},
  pages = {110--141},
  issn = {0730-0301},
  doi = {10.1145/22949.22950},
  urldate = {2025-04-27},
  abstract = {The goal of the research described in this paper is to develop an application-independent presentation tool that automatically designs effective graphical presentations (such as bar charts, scatter plots, and connected graphs) of relational information. Two problems are raised by this goal: The codification of graphic design criteria in a form that can be used by the presentation tool, and the generation of a wide variety of designs so that the presentation tool can accommodate a wide variety of information. The approach described in this paper is based on the view that graphical presentations are sentences of graphical languages. The graphic design issues are codified as expressiveness and effectiveness criteria for graphical languages. Expressiveness criteria determine whether a graphical language can express the desired information. Effectiveness criteria determine whether a graphical language exploits the capabilities of the output medium and the human visual system. A wide variety of designs can be systematically generated by using a composition algebra that composes a small set of primitive graphical languages. Artificial intelligence techniques are used to implement a prototype presentation tool called APT (A Presentation Tool), which is based on the composition algebra and the graphic design criteria.}
}

@misc{mccoleman2021RethinkingRanksVisual,
  title = {Rethinking the {{Ranks}} of {{Visual Channels}}},
  author = {McColeman, Caitlyn M. and Yang, Fumeng and Franconeri, Steven and Brady, Timothy F.},
  year = {2021},
  month = jul,
  number = {arXiv:2107.11367},
  eprint = {2107.11367},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.1109/TVCG.2021.3114684},
  urldate = {2024-03-26},
  abstract = {Data can be visually represented using visual channels like position, length or luminance. An existing ranking of these visual channels is based on how accurately participants could report the ratio between two depicted values. There is an assumption that this ranking should hold for different tasks and for different numbers of marks. However, there is little existing work testing assumption, especially given that visually computing ratios is relatively unimportant in real-world visualizations, compared to seeing, remembering, and comparing trends and motifs, across displays that almost universally depict more than two values. We asked participants to immediately reproduce a set of values from memory. With a Bayesian multilevel modeling approach, we observed how the relevant rank positions of visual channels shift across different numbers of marks (2, 4 or 8) and for bias, precision, and error measures. The ranking did not hold, even for reproductions of only 2 marks, and the new ranking was highly inconsistent for reproductions of different numbers of marks. Other factors besides channel choice far more influence on performance, such as the number of values in the series (e.g. more marks led to larger errors), or the value of each mark (e.g. small values are systematically overestimated). Recall was worse for displays with 8 marks than 4, consistent with established limits on visual memory. These results show that we must move beyond two-value ratio judgments as a baseline for ranking the quality of a visual channel, including testing new tasks (detection of trends or motifs), timescales (immediate computation, or later comparison), and the number of values (from a handful, to thousands).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction,H.5}
}

@article{peterson1954HowAccuratelyAre,
  title = {How {{Accurately Are Different Kinds}} of {{Graphs Read}}?},
  author = {Peterson, Lewis V. and Schramm, Wilbur},
  year = {1954},
  journal = {Audio Visual Communication Review},
  volume = {2},
  number = {3},
  eprint = {30218399},
  eprinttype = {jstor},
  pages = {178--189},
  publisher = {Springer},
  issn = {0885-727X},
  urldate = {2024-03-18},
  url = {https://www.jstor.org/stable/30218399},
}

@article{quadri2022SurveyPerceptionBasedVisualization,
  title = {A {{Survey}} of {{Perception-Based Visualization Studies}} by {{Task}}},
  author = {Quadri, Ghulam Jilani and Rosen, Paul},
  year = {2022},
  month = dec,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {28},
  number = {12},
  pages = {5026--5048},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2021.3098240},
  urldate = {2023-12-08},
  abstract = {Knowledge of human perception has long been incorporated into visualizations to enhance their quality and effectiveness. The last decade, in particular, has shown an increase in perception-based visualization research studies. With all of this recent progress, the visualization community lacks a comprehensive guide to contextualize their results. In this report, we provide a systematic and comprehensive review of research studies on perception related to visualization. This survey reviews perception-focused visualization studies since 1980 and summarizes their research developments focusing on low-level tasks, further breaking techniques down by visual encoding and visualization type. In particular, we focus on how perception is used to evaluate the effectiveness of visualizations, to help readers understand and apply the principles of perception of their visualization designs through a task-optimized approach. We concluded our report with a summary of the weaknesses and open research questions in the area.}
}

@inproceedings{redmond2019VisualCuesEstimation,
  title = {Visual Cues in Estimation of Part-to-Whole Comparison},
  booktitle = {2019 {{IEEE Visualization Conference}} ({{VIS}})},
  author = {Redmond, Stephen},
  year = {2019},
  month = oct,
  eprint = {1908.00630},
  primaryclass = {cs},
  pages = {1--5},
  doi = {10.1109/VISUAL.2019.8933718},
  urldate = {2024-01-19},
  abstract = {Pie charts were first published in 1801 by William Playfair and have caused some controversy since. Despite the suggestions of many experts against their use, several empirical studies have shown that pie charts are at least as good as alternatives. From Brinton to Few on one side and Eells to Kosara on the other, there appears to have been a hundred-year war waged on the humble pie. In this paper a set of experiments are reported that compare the performance of pie charts and horizontal bar charts with various visual cues. Amazon's Mechanical Turk service was employed to perform the tasks of estimating segments in various part-to-whole charts. The results lead to recommendations for data visualization professionals in developing dashboards.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction}
}

@article{simkin1987InformationProcessingAnalysisGraph,
  title = {An {{Information-Processing Analysis}} of {{Graph Perception}}},
  author = {Simkin, David and Hastie, Reid},
  year = {1987},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {82},
  number = {398},
  pages = {454--465},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1987.10478448},
  urldate = {2024-03-06},
  langid = {english}
}

@article{skau2016ArcsAnglesAreas,
  title = {Arcs, {{Angles}}, or {{Areas}}: {{Individual Data Encodings}} in {{Pie}} and {{Donut Charts}}},
  shorttitle = {Arcs, {{Angles}}, or {{Areas}}},
  author = {Skau, Drew and Kosara, Robert},
  year = {2016},
  journal = {Computer Graphics Forum},
  volume = {35},
  number = {3},
  pages = {121--130},
  issn = {1467-8659},
  doi = {10.1111/cgf.12888},
  urldate = {2024-03-06},
  abstract = {Pie and donut charts have been a hotly debated topic in the visualization community for some time now. Even though pie charts have been around for over 200 years, our understanding of the perceptual factors used to read data in them is still limited. Data is encoded in pie and donut charts in three ways: arc length, center angle, and segment area. For our first study, we designed variations of pie charts to test the importance of individual encodings for reading accuracy. In our second study, we varied the inner radius of a donut chart from a filled pie to a thin outline to test the impact of removing the central angle. Both studies point to angle being the least important visual cue for both charts, and the donut chart being as accurate as the traditional pie chart.},
  copyright = {{\copyright} 2016 The Author(s) Computer Graphics Forum {\copyright} 2016 The Eurographics Association and John Wiley \& Sons Ltd. Published by John Wiley \& Sons Ltd.},
  langid = {english}
}

@article{tversky1974JudgmentUncertaintyHeuristics,
  title = {Judgment under {{Uncertainty}}: {{Heuristics}} and {{Biases}}},
  shorttitle = {Judgment under {{Uncertainty}}},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1974},
  journal = {Science},
  volume = {185},
  number = {4157},
  eprint = {1738360},
  eprinttype = {jstor},
  pages = {1124--1131},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  urldate = {2024-03-22},
  URL = {http://www.jstor.org/stable/1738360}
}

@article{valdez2018PrimingAnchoringEffects,
  title = {Priming and {{Anchoring Effects}} in {{Visualization}}},
  author = {Valdez, Andr{\'e} Calero and Ziefle, Martina and Sedlmair, Michael},
  year = {2018},
  month = jan,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {24},
  number = {1},
  pages = {584--594},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2017.2744138},
  urldate = {2024-03-20},
  abstract = {We investigate priming and anchoring effects on perceptual tasks in visualization. Priming or anchoring effects depict the phenomena that a stimulus might influence subsequent human judgments on a perceptual level, or on a cognitive level by providing a frame of reference. Using visual class separability in scatterplots as an example task, we performed a set of five studies to investigate the potential existence of priming and anchoring effects. Our findings show that - under certain circumstances - such effects indeed exist. In other words, humans judge class separability of the same scatterplot differently depending on the scatterplot(s) they have seen before. These findings inform future work on better understanding and more accurately modeling human perception of visual patterns.},
  keywords = {Anchoring,Bias,Cognition,Correlation,Data models,Data visualization,MTurk Study,Perception,Scatterplots,Uncertainty,Visual perception,Visualization}
}

@article{vonhuhn1927FurtherStudiesGraphic,
  title = {Further {{Studies}} in the {{Graphic Use}} of {{Circles}} and {{Bars}}: {{A Discussion}} of the {{Eell}}'s {{Experiment}}},
  shorttitle = {Further {{Studies}} in the {{Graphic Use}} of {{Circles}} and {{Bars}}},
  author = {{von Huhn}, R. and Croxton, Frederick E.},
  year = {1927},
  journal = {Journal of the American Statistical Association},
  volume = {22},
  number = {157},
  eprint = {2277346},
  eprinttype = {jstor},
  pages = {31--39},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2277346},
  urldate = {2024-03-18}
}

@inproceedings{zeng2023ReviewCollationGraphical,
  title = {A {{Review}} and {{Collation}} of {{Graphical Perception Knowledge}} for {{Visualization Recommendation}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zeng, Zehua and Battle, Leilani},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581349},
  urldate = {2024-01-19},
  abstract = {Selecting appropriate visual encodings is critical to designing effective visualization recommendation systems, yet few findings from graphical perception are typically applied within these systems. We observe two significant limitations in translating graphical perception knowledge into actionable visualization recommendation rules/constraints: inconsistent reporting of findings and a lack of shared data across studies. How can we translate the graphical perception literature into a knowledge base for visualization recommendation? We present a review of 59 papers that study user perception and performance across ten visual analysis tasks. Through this study, we contribute a JSON dataset that collates existing theoretical and experimental knowledge and summarizes key study outcomes in graphical perception. We illustrate how this dataset can inform automated encoding decisions with three representative visualization recommendation systems. Based on our findings, we highlight open challenges and opportunities for the community in collating graphical perception knowledge for a range of visualization recommendation scenarios.},
  isbn = {978-1-4503-9421-5},
  keywords = {Human Perception,Literature Review,Visualization Design}
}
